{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification using Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJX+H6JW7YXTLYPY6tiR+5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smfatima/Machine-Learning/blob/main/Supervised%20Learning/Classification_using_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEfirjvhzmge"
      },
      "source": [
        "Classification using Tensorflow of Iris Dataset\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oz2AOIO0gEX"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGrmJaBEdapq"
      },
      "source": [
        "#Import libraries\r\n",
        "from __future__ import (absolute_import, division,\r\n",
        "                        print_function, unicode_literals)\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import tensorflow.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1ZFoSR20K-i"
      },
      "source": [
        "#Load dataset\r\n",
        "csv_coloumn_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\r\n",
        "Species = ['Setosa', 'Versicolor', 'Viriginica']\r\n",
        "\r\n",
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
        "\r\n",
        "train = pd.read_csv(train_path, names=csv_coloumn_names, header = 0)\r\n",
        "test = pd.read_csv(test_path, names=csv_coloumn_names, header = 0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ1LXZlD89nB"
      },
      "source": [
        "train_y = train.pop('Species')\r\n",
        "test_y = test.pop('Species')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "K5QjvrXq8ZeY",
        "outputId": "6db86f48-626f-4c21-82f9-4af8c23e79b3"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cARIrg8x8guk"
      },
      "source": [
        "#Input function\r\n",
        "def train_input_fn(features, labels, training=True, batch_size=256):\r\n",
        "  #convert the input to a dataset\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
        "\r\n",
        "  #shuffle and repeat if ypu are in training mode\r\n",
        "  if training:\r\n",
        "    dataset = dataset.shuffle(1000).repeat()\r\n",
        "    return dataset.batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwj0FPv2_Rl9",
        "outputId": "60397dcb-2cfe-4ac0-84ec-649504ea9793"
      },
      "source": [
        "#feature column\r\n",
        "my_feature_columns = []\r\n",
        "for key in train.keys():\r\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n",
        "print(my_feature_columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEX0s0PgWkH-",
        "outputId": "4c242912-db70-4882-9fdd-991ad4f619f4"
      },
      "source": [
        "#Build a DNN with 2 hidden layers\r\n",
        "\r\n",
        "classifier = tf.estimator.DNNClassifier(\r\n",
        "    feature_columns = my_feature_columns,\r\n",
        "    hidden_units = [30, 10], \r\n",
        "    n_classes = 3\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppj3gg2c3\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppj3gg2c3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ajGMsznXfI9",
        "outputId": "28037fc2-04a8-4c0f-ef22-43db1995556c"
      },
      "source": [
        "#Train the model\r\n",
        "classifier.train(\r\n",
        "    input_fn = lambda: train_input_fn(train, train_y, training = True),\r\n",
        "    steps = 5000\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppj3gg2c3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 1.0587089, step = 0\n",
            "INFO:tensorflow:global_step/sec: 428.801\n",
            "INFO:tensorflow:loss = 0.9031389, step = 100 (0.235 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.4\n",
            "INFO:tensorflow:loss = 0.8555454, step = 200 (0.193 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.239\n",
            "INFO:tensorflow:loss = 0.8218584, step = 300 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 525.191\n",
            "INFO:tensorflow:loss = 0.79668033, step = 400 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.664\n",
            "INFO:tensorflow:loss = 0.7681616, step = 500 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 537.517\n",
            "INFO:tensorflow:loss = 0.7485567, step = 600 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 555.452\n",
            "INFO:tensorflow:loss = 0.7325909, step = 700 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.126\n",
            "INFO:tensorflow:loss = 0.7252251, step = 800 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 522.579\n",
            "INFO:tensorflow:loss = 0.6855891, step = 900 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.958\n",
            "INFO:tensorflow:loss = 0.69145703, step = 1000 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 573.981\n",
            "INFO:tensorflow:loss = 0.66452825, step = 1100 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.818\n",
            "INFO:tensorflow:loss = 0.6519607, step = 1200 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.326\n",
            "INFO:tensorflow:loss = 0.62645394, step = 1300 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 502.027\n",
            "INFO:tensorflow:loss = 0.6244848, step = 1400 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.209\n",
            "INFO:tensorflow:loss = 0.6162726, step = 1500 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 458.305\n",
            "INFO:tensorflow:loss = 0.5980382, step = 1600 (0.221 sec)\n",
            "INFO:tensorflow:global_step/sec: 491.926\n",
            "INFO:tensorflow:loss = 0.59612894, step = 1700 (0.200 sec)\n",
            "INFO:tensorflow:global_step/sec: 521.206\n",
            "INFO:tensorflow:loss = 0.5825, step = 1800 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 503.366\n",
            "INFO:tensorflow:loss = 0.5763768, step = 1900 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 493.156\n",
            "INFO:tensorflow:loss = 0.57123685, step = 2000 (0.203 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.399\n",
            "INFO:tensorflow:loss = 0.5573789, step = 2100 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.984\n",
            "INFO:tensorflow:loss = 0.54758203, step = 2200 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 533.005\n",
            "INFO:tensorflow:loss = 0.5615939, step = 2300 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.113\n",
            "INFO:tensorflow:loss = 0.5383352, step = 2400 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 520.852\n",
            "INFO:tensorflow:loss = 0.53256136, step = 2500 (0.191 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.317\n",
            "INFO:tensorflow:loss = 0.5186087, step = 2600 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 540.829\n",
            "INFO:tensorflow:loss = 0.5112669, step = 2700 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 490.621\n",
            "INFO:tensorflow:loss = 0.51294786, step = 2800 (0.205 sec)\n",
            "INFO:tensorflow:global_step/sec: 481.757\n",
            "INFO:tensorflow:loss = 0.5059451, step = 2900 (0.207 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.177\n",
            "INFO:tensorflow:loss = 0.49386984, step = 3000 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.793\n",
            "INFO:tensorflow:loss = 0.49929634, step = 3100 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 501.313\n",
            "INFO:tensorflow:loss = 0.47538635, step = 3200 (0.196 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.309\n",
            "INFO:tensorflow:loss = 0.47536162, step = 3300 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 560.651\n",
            "INFO:tensorflow:loss = 0.4876781, step = 3400 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 524.907\n",
            "INFO:tensorflow:loss = 0.47818366, step = 3500 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.126\n",
            "INFO:tensorflow:loss = 0.4640324, step = 3600 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.819\n",
            "INFO:tensorflow:loss = 0.4779002, step = 3700 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 541.161\n",
            "INFO:tensorflow:loss = 0.47965065, step = 3800 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.775\n",
            "INFO:tensorflow:loss = 0.4518807, step = 3900 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 499.479\n",
            "INFO:tensorflow:loss = 0.45400113, step = 4000 (0.198 sec)\n",
            "INFO:tensorflow:global_step/sec: 492.975\n",
            "INFO:tensorflow:loss = 0.44463664, step = 4100 (0.201 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.32\n",
            "INFO:tensorflow:loss = 0.44648826, step = 4200 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 536.565\n",
            "INFO:tensorflow:loss = 0.45459142, step = 4300 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 557.96\n",
            "INFO:tensorflow:loss = 0.43599305, step = 4400 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 559.676\n",
            "INFO:tensorflow:loss = 0.43521777, step = 4500 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 515.655\n",
            "INFO:tensorflow:loss = 0.42109323, step = 4600 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 582.329\n",
            "INFO:tensorflow:loss = 0.43091685, step = 4700 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 535.247\n",
            "INFO:tensorflow:loss = 0.42645684, step = 4800 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 504.921\n",
            "INFO:tensorflow:loss = 0.41768712, step = 4900 (0.201 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmppj3gg2c3/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
            "INFO:tensorflow:Loss for final step: 0.41368222.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f3c9a6d16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55EEQA0kZk3E",
        "outputId": "e079f26f-210f-4217-8f4b-61e0de019e33"
      },
      "source": [
        " #prediction\r\n",
        " def input_fn(features, batch_size=256):\r\n",
        "   #convert the inputs to dataset without labels\r\n",
        "   return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\r\n",
        "\r\n",
        "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\r\n",
        "\r\n",
        "predict = {}\r\n",
        "\r\n",
        "print(\"Please type numeric values as prompted.\")\r\n",
        "\r\n",
        "for feature in features:\r\n",
        "  valid=True\r\n",
        "  while valid:\r\n",
        "    val = input(feature + \": \")\r\n",
        "    if not val.isdigit(): valid=False\r\n",
        "  predict[feature] = [float(val)]\r\n",
        "\r\n",
        "predictions = classifier.predict(input_fn = lambda: input_fn(predict))\r\n",
        "for pred_dict in predictions:\r\n",
        "  class_id = pred_dict['class_ids'][0]\r\n",
        "  probability = pred_dict['probabilities'][class_id]\r\n",
        "\r\n",
        "  print('Prediction is \"{}\" ({:.1f}%)'.format(\r\n",
        "      Species[class_id], 100 * probability))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please type numeric values as prompted.\n",
            "SepalLength: 0.5\n",
            "SepalWidth: 0.6\n",
            "PetalLength: 0.7\n",
            "PetalWidth: 0.8\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppj3gg2c3/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (39.8%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}